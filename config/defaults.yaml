# conf/config.yaml
hydra:
  run:
    dir: outputs/${now:%y-%m-%d_%H:%M}_${model.model_name_short}

defaults:
  - model: gpt-4o-mini
  - dataset: scivqaOutputFormat
  - mlflow: scivqa
  - _self_

metrics:
  - F1
  - BLEU:
      n_grams: 1
  - ROUGEDetailed:
      rouge_type: rouge1
  - ROUGEDetailed:
      rouge_type: rougeL
  - BERTScore:
      lang: en
  - GeneratedAnswerLength
  - ExactMatch

output_folder: outputs/${now:%y-%m-%d_%H:%M}_${model.model_name_short}
template_folder: /scivqa
template_name: /src/scivqa/prompts/templates/version_v7.j2
use_vllm: false
base_url: http://localhost:${vllm_port}/v1/
vllm_port: 15868
apply_few_shot: false
few_shot_template: /scivqa/src/scivqa/prompts/templates/few_shot_v1.j2
few_shot_dataset_path: /scivqa/data/train_2025-03-27_18-34-44.json
few_shot_images_path: /scivqa/data/train

# config f√ºr finetunedOhneUnsloth Inference Server
adapter_path: "/SciVQA/unsloth/Qwen2_5_7B_r64_a64_d0_1"
#adapter_path : "/SciVQA/unsloth/Qwen2_5_32B-8bitChangedR"
#adapter_path : "/SciVQA/unsloth/Qwen2_5_32B-8bit_sysPrompt11"
#adapter_path : "/SciVQA/unsloth/Qwen2_5_32B-8bit_2Epochs"
#model_id : "Qwen/Qwen2.5-VL-32B-Instruct"
model_id : "Qwen/Qwen2.5-VL-7B-Instruct"
